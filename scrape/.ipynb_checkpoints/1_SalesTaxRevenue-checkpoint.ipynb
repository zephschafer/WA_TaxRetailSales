{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape WA DOR Tax Sales Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Scrape\n",
    "#### (2) Clean and Compile\n",
    "#### (3) Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- IMPORT_REQUIREMENTS ----- \n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from time import sleep\n",
    "import requests\n",
    "import lxml.html\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- SPECIFY_OUTPUT_LOCATION ----- \n",
    "\n",
    "output = '../static/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0100', '0101', '0102', '0103', '0104']\n",
      "Number of Counties: 342\n"
     ]
    }
   ],
   "source": [
    "# ----- Get_County_Codes ----- \n",
    "\n",
    "# From the point-and-click county filter on the original website,\n",
    "# scrape the list of counties\n",
    "site_query_options = lxml.html.fromstring(requests\\\n",
    "                                          .get('https://apps.dor.wa.gov/'\\\n",
    "                                               +'ResearchStats/Content/'\\\n",
    "                                               +'TaxableRetailSalesLocal/'\\\n",
    "                                               +'Report.aspx').content)\\\n",
    "                                    .xpath('//option')\n",
    "county_codes = []\n",
    "\n",
    "# This method depends on the explicit reference to the index of the rows\n",
    "# in which the county names occur. That makes it vulnerable to any\n",
    "# superficial changes in the design of the source page, but works for now.\n",
    "for county_n in range(68,409):\n",
    "    county_codes.append(site_query_options[county_n].text_content()[0:4])\n",
    "county_codes.append('Statewide')\n",
    "print(county_codes[0:5]) # just a snippet of what we've got\n",
    "print 'Number of Counties: '+ str(len(county_codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Create_List_of_Year_for_the_UL ----- \n",
    "\n",
    "dates_list = [str(year) + str(datetype)\n",
    "         for year in range(2005,2017)\n",
    "         for datetype in ['AN','Q1','Q2','Q3','Q4']]\n",
    "dates_str = ''\n",
    "for i in dates_list:\n",
    "    dates_str = dates_str + ',' + str(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Define_Scrape_Function_for_Sales_Data ----- \n",
    "\n",
    "def scrape_sales_data(url):\n",
    "    geturl = requests.get(url)\n",
    "    page = lxml.html.fromstring(geturl.content)\n",
    "    tr_elements = page.xpath('//tr')\n",
    "    if (\"That request does not appear to match any records in the database.\" \\\n",
    "              in geturl.text) or ('Runtime Error' in geturl.text):\n",
    "        df = pd.DataFrame({'col1': [1]})\n",
    "        return df\n",
    "    else:\n",
    "        col=[]\n",
    "        for t in tr_elements[0]:\n",
    "            name = t.text_content()\n",
    "            col.append((name,[]))\n",
    "        for j in range(1,len(tr_elements)):\n",
    "            T = tr_elements[j]\n",
    "            if len(T) != 5:\n",
    "                break\n",
    "            i = 0\n",
    "            for t in T.iterchildren():\n",
    "                data = t.text_content() \n",
    "                col[i][1].append(data)\n",
    "                i += 1\n",
    "            Dict = {title:column for (title,column) in col}\n",
    "            df = pd.DataFrame(Dict)\n",
    "        string = geturl.text\n",
    "        newstring_a = re.search('''  Location: <span id=\"MainContent_lblLoc\">''' \\\n",
    "                                + '.*' + '<', string).group(0)\n",
    "        newstring_b = re.sub('''  Location: <span id=\"MainContent_lblLoc\">''',''\\\n",
    "                                         , newstring_a)\n",
    "        newstring_c = re.sub('''<''','', newstring_b)\n",
    "        df['location_name'] = newstring_c\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e3ab344f22b4c2599a6ffc64dcd4c80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=342), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ----- Execute_Scrape ----- \n",
    "\n",
    "results = []\n",
    "i = 0\n",
    "export_count = 1\n",
    "for naicstyp in ['2']:\n",
    "    for county in tqdm(county_codes):\n",
    "        sleep(2)\n",
    "        if county=='Statewide':\n",
    "            location = ''\n",
    "        else:\n",
    "            location = '&Location=' + county\n",
    "        url = str(\"http://apps.dor.wa.gov/ResearchStats/Content/TaxableRetailSalesLocal\" \\\n",
    "                  + \"/Results.aspx?Year=2018Q1,2017Q4\"\\\n",
    "                  + dates_str\n",
    "                  + \"&Code1=11&Code2=99&Sumby=n\" \\\n",
    "                  + str(naicstyp) + \"&SicNaics=2\" + location \\\n",
    "                  + \"&Format=HTML&TaxType=45\")\n",
    "        try:\n",
    "            df = scrape_sales_data(url)\n",
    "        except: \n",
    "            sleep(45)\n",
    "            df = scrape_sales_data(url)\n",
    "        checkpoint = '1_' + str(county) + str(i)\n",
    "        if len(df) == 1:\n",
    "            results.append(county + ' is Empty')\n",
    "        else:\n",
    "            results.append(str(df['location_name'][1]) + str(county))\n",
    "            df['location_id'] = county\n",
    "            df['naicstyp'] = str(naicstyp)\n",
    "            if i == 0:\n",
    "                salestaxrev = df\n",
    "            else:\n",
    "                salestaxrev = salestaxrev.append(df)\n",
    "            i += 1\n",
    "            if salestaxrev['location_id'].memory_usage() >= 100000:\n",
    "                salestaxrev.to_csv(output + 'slices/salestaxrev_' \\\n",
    "                                   + str(export_count) + '.csv')\n",
    "                del salestaxrev\n",
    "                checkpoint = '3_' + str(export_count) + str(i)\n",
    "                export_count += 1\n",
    "                i = 0\n",
    "                checkpoint = ' ---Export---' + str(export_count) + '---'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Get_NAICS_Code_Names ----- \n",
    "# Get Category Names\n",
    "tr = lxml.html.fromstring(requests.get('https://www.naics.com/search/').content).xpath('//tr')\n",
    "# naics table is the first 22 rows, minus the first header row\n",
    "names = []\n",
    "codes = []\n",
    "for row in range(1,21):\n",
    "    codes.append(tr[row][0].text_content())\n",
    "    names.append(tr[row][1].text_content())\n",
    "df = pd.DataFrame(data = {'codes': codes, 'names': names})\n",
    "# Resolve Ranges (e.g. Retail Trade is '44-45')\n",
    "df = df.replace({'31-33': '31', '44-45': '44', '48-49':'48'})\n",
    "appendage = pd.DataFrame(data = {'codes': ['32','33','45','49','99'],\\\n",
    "                                  'names': ['Manufacturing','Manufacturing','Retail Trade'\\\n",
    "                                            ,'Transportation and Warehousing','Other Govmt.']})\n",
    "naics_lookup = df.append(appendage).sort_values(by='codes')\n",
    "# Convert Codes to Int\n",
    "naics_lookup['codes'] = naics_lookup['codes'].astype(int)\n",
    "# Create Groups According to ad hoc Preference\n",
    "naics_lookup['short_names'] = naics_lookup.names.replace({'Agriculture, Forestry, Fishing and Hunting': 'Ag. and Forestry'\\\n",
    "                                , 'Transportation and Warehousing': 'Distribution'\\\n",
    "                                , 'Finance and Insurance':'FIRE'\\\n",
    "                                , 'Real Estate Rental and Leasing':'FIRE'\\\n",
    "                                , 'Professional, Scientific, and Technical Services':'Services'\n",
    "                                , 'Management of Companies and Enterprises':'Services'\n",
    "                                , 'Administrative and Support and Waste Management and Remediation Services':'Admin Support'\\\n",
    "                                , 'Educational Services':'Education'\\\n",
    "                                , 'Health Care and Social Assistance':'Health Care'\\\n",
    "                                , 'Arts, Entertainment, and Recreation':'Arts and Entertainment'\\\n",
    "                                , 'Accommodation and Food Services': 'Hospitality'\\\n",
    "                                , 'Other Services (except Public Administration)':'Other Private'\\\n",
    "                                , 'Public Administration':'Government'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Compile and Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Compile_Slices ----- \n",
    "\n",
    "i = 1\n",
    "for file_n in range(1,export_count):\n",
    "    file = 'slices/salestaxrev_' + str(file_n) + '.csv'\n",
    "    temp = pd.read_csv(output + file)\n",
    "    for var in ['Total Taxable','Units']:\n",
    "        temp[var] = temp[var].str.replace('$','')\n",
    "        temp[var] = temp[var].str.replace(',','')\n",
    "        temp[var] = temp[var].str.replace('D','0')\n",
    "        temp[var] = temp[var].astype('int64')\n",
    "    temp['location_name'] = temp['location_name'].str.replace('/span>','')\n",
    "    if i == 1:\n",
    "        salestaxrev = temp\n",
    "        i += 1\n",
    "    else:\n",
    "        salestaxrev = pd.concat([salestaxrev,temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Clean_Compilation ----- \n",
    "# Clean County Info\n",
    "salestaxrev['county'] = salestaxrev['location_name'].str.contains('Unincorporated')\n",
    "salestaxrev['county_name'] = salestaxrev['location_name'].where(salestaxrev['county'])\\\n",
    "    .str.replace('Unincorporated ','').ffill()\n",
    "salestaxrev.drop(columns=['county','Unnamed: 0'],inplace=True)\n",
    "# Add a State Column (Feels orderly. And it may be useful later)\n",
    "salestaxrev['state'] = 'WA'\n",
    "# Distinguish Between Quarterly and Annual\n",
    "salestaxrev['datetyp'] = salestaxrev['Year'].replace(regex={'.* Quarter .':'Q'\\\n",
    "                                                            ,'.* Annual*.*': 'A'})\n",
    "# Format Dates as Dates\n",
    "salestaxrev['date'] = pd.to_datetime(salestaxrev['Year'].\n",
    "                                     replace(regex={' Quarter 1':'/1/1',' Quarter 2':'/4/1'\\\n",
    "                                                    ,' Quarter 3':'/7/1',' Quarter 4':'/10/1'\\\n",
    "                                                    ,' Annual*.*':''}))\n",
    "# Clean var names\n",
    "salestaxrev = salestaxrev.rename(index=str, columns={'Total Taxable':'sales','NAICS':'naics'\\\n",
    "                                                     ,'Units':'units','naicstyp':'naics_typ'})\n",
    "# Keep only wanted columns\n",
    "salestaxrev = salestaxrev[['state','location_name','location_id','county_name','datetyp'\\\n",
    "                           ,'date','naics_typ','naics','sales','units']]\n",
    "# Merge NAICS\n",
    "salestaxrev = salestaxrev.merge(naics_lookup, left_on='naics', right_on='codes', how='left')\\\n",
    "                                    .drop(columns = ['names','codes'])\n",
    "# Create a Quarterly and Annual \n",
    "salestaxrev_qtrly = salestaxrev[salestaxrev.datetyp == 'Q']\n",
    "salestaxrev_annual = salestaxrev[salestaxrev.datetyp == 'A']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Tables_6 files ----- \n",
    "# ----- Group_Across_Place ----- \n",
    "# (As will be obvious to any reader, this should be in a loop. It just hasn't been made yet)\n",
    "# N1\n",
    "salestaxrev_qtrly.to_csv(output + 'SalTaxRev_WA_place_N1_qtrly' + '.csv', index=0)\n",
    "salestaxrev_annual.to_csv(output + 'SalTaxRev_WA_place_N1_annl' + '.csv', index=0)\n",
    "# N0\n",
    "salestaxrev_qtrly[['date','county_name','location_name','location_id','sales','units']]\\\n",
    "    .groupby(['county_name','location_name','location_id','date']).sum().reset_index()\\\n",
    "    .to_csv(output + 'SalTaxRev_WA_place_N0_qtrly' + '.csv', index=0)\n",
    "salestaxrev_annual[['date','county_name','location_name','location_id','sales','units']]\\\n",
    "    .groupby(['county_name','location_name','location_id','date']).sum().reset_index()\\\n",
    "    .to_csv(output + 'SalTaxRev_WA_place_N0_annl' + '.csv', index=0)\n",
    "# ----- Group_Across_County ----- \n",
    "# N1\n",
    "salestaxrev_qtrly[['date','county_name','naics','short_names','sales','units']]\\\n",
    "    .groupby(['county_name','short_names','naics','date']).sum().reset_index()\\\n",
    "    .to_csv(output + 'SalTaxRev_WA_state_N1_qtrly' + '.csv', index=0)\n",
    "salestaxrev_annual[['date','county_name','naics'\\\n",
    "                    ,'short_names','sales','units']]\\\n",
    "    .groupby(['county_name','short_names','naics','date']).sum().reset_index()\\\n",
    "    .to_csv(output + 'SalTaxRev_WA_county_N1_annl' + '.csv', index=0)\n",
    "# N0\n",
    "salestaxrev_qtrly[['date','county_name','sales','units']]\\\n",
    "    .groupby(['county_name','date']).sum().reset_index()\\\n",
    "    .to_csv(output + 'SalTaxRev_WA_state_N0_qtrly' + '.csv', index=0)\n",
    "salestaxrev_annual[['date','county_name','naics','sales','units']]\\\n",
    "    .groupby(['county_name','date']).sum().reset_index()\\\n",
    "    .to_csv(output + 'SalTaxRev_WA_county_N0_annl' + '.csv', index=0)\n",
    "# ----- Group_Across_State ----- \n",
    "# N1\n",
    "salestaxrev_qtrly[['date','state','naics','short_names','sales','units']]\\\n",
    "    .groupby(['naics','short_names','date']).sum().reset_index()\\\n",
    "    .to_csv(output + 'SalTaxRev_WA_state_N1_qtrly' + '.csv', index=0)\n",
    "SalTaxRev_WA_state_N1_annl = salestaxrev_annual[['date','state','naics','short_names'\\\n",
    "                                                 ,'sales','units']]\\\n",
    "    .groupby(['naics','short_names','date']).sum().reset_index()\\\n",
    "    .to_csv(output + 'SalTaxRev_WA_state_N1_annl' + '.csv', index=0)\n",
    "# N0\n",
    "salestaxrev_qtrly[['date','state','sales','units']]\\\n",
    "    .groupby(['date']).sum().reset_index()\\\n",
    "    .to_csv(output + 'SalTaxRev_WA_state_N0_qtrly' + '.csv', index=0)\n",
    "salestaxrev_annual[['date','state','sales','units']]\\\n",
    "    .groupby(['date']).sum().reset_index()\\\n",
    "    .to_csv(output + 'SalTaxRev_WA_state_N0_annl' + '.csv', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zephschafer/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "# ----- Export_to_suit_the_Viz ----- \n",
    "\n",
    "df1 = pd.read_csv(output + 'SalTaxRev_WA_county_N1_annl.csv')\\\n",
    "        .groupby(['county_name','short_names','date']).sum().reset_index()\n",
    "df1['date'] = pd.to_datetime(df1.date).dt.strftime('%m/%d/%y')\n",
    "df1['statewide'] = 'Statewide'\n",
    "df2 = df1.groupby(['statewide','short_names','date'])\\\n",
    "        .sum().reset_index()\\\n",
    "        .rename(index=str, columns={\"statewide\": \"county_name\"})\n",
    "df3 = df1.append(df2)\n",
    "df4 = df3.rename(columns={\"date\":\"year\",\"county_name\":\"county\"})\n",
    "STR_WA_C_N1_A_W = pd.pivot_table(df4, values='sales', \\\n",
    "                    index=['year','county'], columns='short_names')\n",
    "STR_WA_C_N1_A_W.to_csv(output + 'STR_WA_C_N1_A_W' + '.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
